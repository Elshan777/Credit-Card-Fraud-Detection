{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook I will present my models which used for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "und = RandomUnderSampler()\n",
    "X_und, y_und = und.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 492, 1: 492})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_und)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88389.0</td>\n",
       "      <td>-3.708227</td>\n",
       "      <td>3.670773</td>\n",
       "      <td>-3.267675</td>\n",
       "      <td>-1.057623</td>\n",
       "      <td>-0.531656</td>\n",
       "      <td>0.465471</td>\n",
       "      <td>-1.261994</td>\n",
       "      <td>2.688371</td>\n",
       "      <td>0.276476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440956</td>\n",
       "      <td>1.537195</td>\n",
       "      <td>0.233305</td>\n",
       "      <td>-1.604590</td>\n",
       "      <td>-0.390139</td>\n",
       "      <td>-0.089148</td>\n",
       "      <td>0.482076</td>\n",
       "      <td>0.182497</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42453.0</td>\n",
       "      <td>-0.237118</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>1.254576</td>\n",
       "      <td>-1.556033</td>\n",
       "      <td>-0.273281</td>\n",
       "      <td>-1.211332</td>\n",
       "      <td>0.301910</td>\n",
       "      <td>-0.275672</td>\n",
       "      <td>-0.889120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040419</td>\n",
       "      <td>0.208583</td>\n",
       "      <td>-0.077185</td>\n",
       "      <td>0.289889</td>\n",
       "      <td>-0.026483</td>\n",
       "      <td>-0.472985</td>\n",
       "      <td>0.102522</td>\n",
       "      <td>-0.121395</td>\n",
       "      <td>24.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80490.0</td>\n",
       "      <td>1.160366</td>\n",
       "      <td>0.037970</td>\n",
       "      <td>0.557385</td>\n",
       "      <td>0.518714</td>\n",
       "      <td>-0.484127</td>\n",
       "      <td>-0.355001</td>\n",
       "      <td>-0.229549</td>\n",
       "      <td>0.162624</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184544</td>\n",
       "      <td>-0.616960</td>\n",
       "      <td>0.199718</td>\n",
       "      <td>0.172904</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.099903</td>\n",
       "      <td>-0.026926</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43887.0</td>\n",
       "      <td>-6.466280</td>\n",
       "      <td>-5.120985</td>\n",
       "      <td>0.881461</td>\n",
       "      <td>-0.412296</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>0.302638</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>-0.799876</td>\n",
       "      <td>0.722063</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.191141</td>\n",
       "      <td>0.793610</td>\n",
       "      <td>1.395308</td>\n",
       "      <td>-0.153513</td>\n",
       "      <td>1.115056</td>\n",
       "      <td>-0.264281</td>\n",
       "      <td>-1.170124</td>\n",
       "      <td>2.766348</td>\n",
       "      <td>253.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67504.0</td>\n",
       "      <td>1.250800</td>\n",
       "      <td>-1.222272</td>\n",
       "      <td>1.714089</td>\n",
       "      <td>-0.223284</td>\n",
       "      <td>-2.182890</td>\n",
       "      <td>0.285805</td>\n",
       "      <td>-1.781897</td>\n",
       "      <td>0.463338</td>\n",
       "      <td>0.725618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182862</td>\n",
       "      <td>0.757754</td>\n",
       "      <td>-0.055848</td>\n",
       "      <td>0.566429</td>\n",
       "      <td>0.358175</td>\n",
       "      <td>-0.069724</td>\n",
       "      <td>0.070048</td>\n",
       "      <td>0.015238</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  88389.0 -3.708227  3.670773 -3.267675 -1.057623 -0.531656  0.465471   \n",
       "1  42453.0 -0.237118  0.223022  1.254576 -1.556033 -0.273281 -1.211332   \n",
       "2  80490.0  1.160366  0.037970  0.557385  0.518714 -0.484127 -0.355001   \n",
       "3  43887.0 -6.466280 -5.120985  0.881461 -0.412296  0.023292  0.302638   \n",
       "4  67504.0  1.250800 -1.222272  1.714089 -0.223284 -2.182890  0.285805   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0 -1.261994  2.688371  0.276476  ...  0.440956  1.537195  0.233305 -1.604590   \n",
       "1  0.301910 -0.275672 -0.889120  ...  0.040419  0.208583 -0.077185  0.289889   \n",
       "2 -0.229549  0.162624  0.021896  ... -0.184544 -0.616960  0.199718  0.172904   \n",
       "3  0.745833 -0.799876  0.722063  ... -1.191141  0.793610  1.395308 -0.153513   \n",
       "4 -1.781897  0.463338  0.725618  ...  0.182862  0.757754 -0.055848  0.566429   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.390139 -0.089148  0.482076  0.182497    1.79      0  \n",
       "1 -0.026483 -0.472985  0.102522 -0.121395   24.90      0  \n",
       "2  0.030826  0.099903 -0.026926  0.003737    0.89      0  \n",
       "3  1.115056 -0.264281 -1.170124  2.766348  253.68      0  \n",
       "4  0.358175 -0.069724  0.070048  0.015238    4.80      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets concat undersampled X and y\n",
    "df_und = pd.concat([X_und, y_und], axis=1)\n",
    "df_und.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets build our first Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = {\n",
    "    'DecisionTreeClassifier' : DecisionTreeClassifier(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'GaussianNB' : GaussianNB(),\n",
    "    'LogisticRegression' : LogisticRegression(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_und, y_und)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier ROC SCORE 0.8862809917355371\n",
      "KNeighborsClassifier ROC SCORE 0.6052231404958679\n",
      "GaussianNB ROC SCORE 0.9654876033057851\n",
      "LogisticRegression ROC SCORE 0.9474380165289256\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in algos.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_predicted=pipeline.predict_proba(X_test)\n",
    "    print(name,'ROC SCORE', roc_auc_score(y_test, y_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can see Gaussian Naive Bayes along side with Logistic regression performed well on the data\n",
    "### Now I will try ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensem = {\n",
    "    'RandomForestClassifier' : RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'LGBMClassifier' : LGBMClassifier(),\n",
    "    'CatBoostClassifier' : CatBoostClassifier(verbose=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier ROC SCORE 0.9655537190082645\n",
      "GradientBoostingClassifier ROC SCORE 0.9704462809917356\n",
      "LGBMClassifier ROC SCORE 0.9678016528925619\n",
      "CatBoostClassifier ROC SCORE 0.9726942148760331\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in ensem.items():\n",
    "    pipe_en = Pipeline(steps=[\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    pipe_en.fit(X_train, y_train)\n",
    "    y_predicted=pipe_en.predict_proba(X_test)\n",
    "    print(name,'ROC SCORE', roc_auc_score(y_test, y_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accuracy might change depending on train test split so we will try cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'GaussianNB' : GaussianNB(),\n",
    "    'LogisticRegression' : LogisticRegression(solver='lbfgs', max_iter=100 ),\n",
    "    'RandomForestClassifier' : RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'LGBMClassifier' : LGBMClassifier(),\n",
    "    'CatBoostClassifier' : CatBoostClassifier(verbose=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: 0.965252 (0.032131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\egadi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.970970 (0.026409)\n",
      "RandomForestClassifier: 0.975022 (0.026845)\n",
      "GradientBoostingClassifier: 0.976508 (0.023652)\n",
      "LGBMClassifier: 0.972043 (0.026710)\n",
      "CatBoostClassifier: 0.978477 (0.022780)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    skfold = StratifiedKFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_und, y_und, cv=skfold, scoring='roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the EDA notebook we saw that dimensionality reduction techniques were useful. Let's try predicting on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_und[['V12', 'V14', 'V10', 'V11', 'V17']]\n",
    "y_new = df_und.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: 0.960429 (0.034630)\n",
      "LogisticRegression: 0.959548 (0.027139)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForestClassifier: 0.956959 (0.037925)\n",
      "GradientBoostingClassifier: 0.956636 (0.031182)\n",
      "LGBMClassifier: 0.952819 (0.038367)\n",
      "CatBoostClassifier: 0.958152 (0.030567)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    skfold = StratifiedKFold(n_splits=10)\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('dim_red', PCA()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    cv_results = cross_val_score(pipeline, X_new, y_new, cv=skfold, scoring='roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: 0.963266 (0.029932)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egadi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.958960 (0.029106)\n",
      "RandomForestClassifier: 0.958221 (0.034424)\n",
      "GradientBoostingClassifier: 0.937576 (0.051871)\n",
      "LGBMClassifier: 0.952439 (0.035453)\n",
      "CatBoostClassifier: 0.956920 (0.030310)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    skfold = StratifiedKFold(n_splits=10)\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('dim_red', PCA()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    cv_results = cross_val_score(pipeline, X_new, y_new, cv=skfold, scoring='roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
